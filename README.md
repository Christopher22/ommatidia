# Ommatidia: Improving generalizability for pupil detection algorithms in head-mounted eye tracking
## Introduction
Eye-tracking is a ubiquitous technology to record, assess, and evaluate eye movements, gazes, and pupil reactions in a magnitude of different research fields [@punde2017]. Historically, corresponding pipelines aimed for otherwise hardly measurable quantities like attention [@TODO] or memory [@TODO]. However, the technology starts to be more widely applied as an invaluable aid for optimized human-computer interaction and experiments in more applied scientific areas like medicine [@larrazabal2019]. Consequently, the growing demand for objective measurements fuels the development of required technology in research and industry [@TODO]. With reduced costs, fewer complexities, and improved accuracy, the technology will presumably get even more prevalent in the future [@TODO].

Stationary eye trackers are generally researched for scientific purposes since the late 19th century [@cognolato2018]. More recently, head-mounted video oculography evolved as a valuable alternative allowing former impossible experimental setups [@cazzato2020a]. Fueled by the minimalization of optical technology, cameras inbuild in glasses-like devices or virtual reality headsets record the eyes constantly with non-visible near-infrared light. Unlike the popular yet proprietary devices used before, the complete process of recording is transparent and re-evaluable accordingly to advances in analysis methods. Additionally, affordable off-the-shelve technology is available or could straightforwardly tailormade [i.e. @zandi2021; @stengel2015]. Consequently, the technology directly supports the four principal components of open science [@vicente-saez2018].

The downside of such great flexibility and archivable tailor-made solutions is the responsibility to tune those magnitudes of factors influencing the actual recording process. Besides the physical camera setup, the pupil detection algorithms represent the primary component of the eye-tracking pipeline. Despite the apparent simplicity of detecting the corresponding blob of pixels in a near-infrared image, this task is challenging and far from being solved. Factors such as contact lenses, dust, makeup, and other external factors induce further complications in the measurement process [@tonsen2016]. Given the magnitude of available algorithms with different advantages and disadvantages, the researcher must choose the method and associated hyperparameters optionally matching its aim [@chen2019]. Guiding those choices given reliable evidence and ease of application define the aim of this publication.

## Challenges with pupil data
Due to various reasons, a decent recording and appropriate analysis of eye-tracking data is not a trivial task. However, those well-known complexities lead to a considerable collection of published knowledge and pieces of advice in literature. Those published insights into possible recording setups, optimization strategies regarding data quality, and analysis methods allow valuable hints towards the proper use of the powerful methodology. Consequently, any researcher striving to apply it could build upon a vivid ecosystem of scientific work.

Supporting the applied researcher in choosing a particular pupil detection algorithm for the measurement pipeline, some evaluation surveys try to compare and rate those algorithms. Using similar evaluation criteria as the developers of the algorithms, the authors provide valuable additional evidence regarding the performance without any bias slipping in unintentionally. In general terms, those reviews document the expected continous improvement of the algorithms due to rising complexity and available data. Still, the ways of analyses do not vary significantly to the original papers. Consequently, the performance of the algorithms is based upon an assumed generalizibility given multiple datasets.

Different datasets for such an evaluation exists due to the diversity of potential recording designs. Most of those were used for training or evaluating a pupil detection algorithm. Consequently, they differ in the types of labels associated with the sample depending on the three major types of algorithms.
Most fundamental is the detected pupil center within the image. Given these two-dimensional coordinates and a (commonly estimated) three-dimensional model of the eye, subsequent procedures can calculate the corresponding rotation of the eye. 
If pupil size matters as in pupillograpy, the algorithms normally yield the best-fitting ellipse enclosing the pupil. The output contains the size of the major and minor axis and its rotation in addition to the two-dimensional position.
The most versatile representation utilizes a segmentation map over the complete sample. This segmentation mask corresponds to a binary mask where only the pupil is indicated. Partly, those algorithm plot algorithms yield output even for other components of the eye like the iris and sclera. In theory, such encoding would allow for partially invisible due to eyelids or blinks.
Crucially, these three different types of annotation create a hierarchy. While the segmentation mask contains most information, reducing it to an ellipse is possible. 

Different datasets for such an evaluation exists due to the diversity of potential recording designs. Most of those were used for training or evaluating a pupil detection algorithm. Consequently, they differ in the types of labels associated with the sample depending on the three major types of algorithms.
Most fundamental is the detected pupil center within the image. Given these two-dimensional coordinates and a (commonly estimated) three-dimensional model of the eye, subsequent procedures can calculate the corresponding rotation of the eye. 
If pupil size matters like in pupillograpy, the algorithms typically yield the best-fitting ellipse enclosing the pupil. The output contains the size of the major and minor axis and its rotation in addition to the two-dimensional position.
The most versatile representation utilizes a segmentation map over the complete sample. This segmentation mask corresponds to a binary mask where only the pupil is indicated. Partially, those algorithms yield similar data for other components of the eye like the iris and sclera, too. In theory, such encoding would even permit using pupils partially hidden due to eyelids or blinks.
Crucially, these three different annotations create a hierarchy regarding their information. While the segmentation mask contains most information, reducing it to an ellipse or even the pupil center is feasible. Given large annotated datasets, researchers rely on the fact algorithms performing well on them will generalize well on unseen setups and subjects, too.

The concept of generalizability is crucial for such an assumption. However, there is no guarantee sufficient performance on other datasets will lead to sufficient performance on the custom setup, too. Instead, different authors highlighted the importance of custom adaptations required for sufficient performance. These complexities result from a magnitude of different aspects:
-   The recorded samples differ significantly based on the position of the camera, its resolution, and distance. Consequently, those of different recording setups are not directly comparable. Given the non-linear transformation of the pupil once viewed from larger eye angles, the performance of the algorithms might be significantly more challenging.
-   The algorithms often require the setting of hyperparameters depending on the samples. Many of those are directly related to semantical meaning Ã¢nd tailored to the specific position of the camera. While reusing those values published may be sufficient if the setups are similar enough, getting more suitable detections will likely depend upon tuning those values.
-   The population of the subjects may differ considerably. Especially in the medical context, specific correlated phenotypes may seriously hinder the detection rate. Published work like TODO systematically evaluating induced bias is still scarce. Furthermore, even within the general population, such challenges are well-documented [TODO]. As an example, measuring specifically subjects with contact lenses requires detectors to perform well even in this specific condition without inducing any bias.
-   The metrics used for performance evaluation differ significantly between studies. Often, they were chosen for optimally assessing a specific dataset or use case. For instance, the evaluation paper by [TODO] used a threshold of five pixels for classifying the detection of the pupil center inside a sample as correct. Given the tested datasets, this is a thoroughly sound decision. However, samples with significantly different resolutions due to another camera setup require the adoption of such concepts.

Given those complexities, the evaluation of pupil detection algorithms must consider their context. Claiming generally superior performance in direct comparison with all competitors appears challenging. Consequently, custom considerations and evaluations in the application of pupil detection algorithms remain necessary.

Besides the hypothetical overall performance, other key concepts influence the decision in favor of one or another pupil detection algorithm. Those other factors arise analogously to other use cases of machine learning where softer concepts start to play a role, too [@cazzato2020a].
Transparency is an example of such an additional dimension. When applied in sensible medical areas, understanding the reasons regarding a specific output might be required.
Another reason is suitable licensing. Some algorithms are licensed for non-commercial usage only. Even in academia, such a license would be incompatible with classical open-source licenses like the GPL. Their requirement regarding re-licensing under the same terms would probit the proper publication required for transparent science. 
Considering those facts further complicates the appropriate choice of a pupil detector besides the assumed detection performance.

Considering all those factors when choosing one out of the many available pupil detection algorithms remains a challenge. Choosing whether to stick to a popular default or choose and tune the algorithm for optimal performance might depend on the precise specification of the project. However, even the soundest knowledge regarding the literature might not be sufficient in the latter case. Consequently, empowering an applied researcher to select and fit the best-fitting detector for the research is the primary contribution of this paper.

## Unifying framework for the assessment of pupil detection algorithms
The aim of this publication is the empowerment if the practitioners from various disciplines towards the independent assessment of pupil detection algorithms. Without deeper knowledge regarding the codebase, having various state-of-the-art variants must be present. Under the premise, they should be able to select the optimal detector with the needs with the minimal effort required to bring the theory into practice. The usefulness of the framework will then be demonstrated on a real example.

The framework must be able to represent all those kinds of detections provided by the different pupil detectors. Due to their different aims, most eye tracker yield one out of three different types of annotation. Most fundamental is the pupil center within the image. Given these two-dimensional coordinates and a (commonly estimated) three-dimensional model of the eye, eye tracker can calculate the corresponsing rotation of the eye. If pupil size matters, the algorithms normally yield the best fitting elipse. Additional to the two-dimensional position, the size of the major and minor axis and rotation are available for the corresponding calculation. The most versatile representation utilizes a segmentation map over the complete image. While some algorithms yield output even for the iris and sclera, this segmentation mask corresponds to a binary mask where only the pupil in indicated. Crutially, this three different types of annotation create a hierchy. Consequently, casting from the binary mask over the ellipse to the pupil center is implemented within the framwork to allow comparison of those pupil detectors otherwise not directly comparable given the smallest common devisor.

We propose a framework inspired by the current developments regarding microservices and distributed computing. These design criterions are enforced to provide a reasonable foundation for individual experiments.
-	The framework must be as hardware independent as possible. Applied researchers should be able to use it on the system already used for the other parts of the experiment conducted. Consequently, support both on UNIX-based systems like Ubuntu or macOS and Microsoft Windows is required. Limiting the necessarity for changes regarding the system, it should induce error-robustness and simplify the usage in practice.
-	Providing a straightforward experience by this is only one part of the general strategy. In the best case, the researcher should only require installing a single software instead of all the different algorithms, their dependencies and build tools. Given those simplicity, gained results should be faster and easier archivable.
-	Given the large number of samples in recent datasets, the mere number of different algorithms, and the number of tunable hyperparameters, the proposed framework must scalable. Given the resources available, it must be able to benefit from a single machine, multiple virtual machines and even a cluster of physical devices. the independence of algorithms and samples leads to easily archivable parallelization of the detections. Consequently, a broader exploration of the search space with algorithms and hyper parameters is possible.
-	The framework should be modular and base upon existing standards. The corresponding documentation does simplify the support of the individual components. More crucially, it does allow the re-use of the system without the necessarity for the usage of the system as hole. For example, after the successful selection of an implementation, such implementation could be used inside the final experiment, too.
-	The framework should be easily adoptable not only for those using pupil detection algorithms but for those developing them. Given the larger number of competitors, the authors may gain important insights for their optimization. Additionally, the risk of involuntary selection bias is reduced given the strictly reproducible nature of the framework. As such, the it may contribute to a sustainable development of the scientific area.

Given those constraint, a Container-based setup appears appealing. The rest of the section will describe the details of those modular, scalar and easily adoptable framework.

### Selection of the pupil detection algorithms
For a mostly completely collection of state-of-the-art algorithms, we utilize the extensive overview by TODO. The fundamental idea is the assumption of as few assumptions as possible. Realtime processing as sometimes enforced is explicitly not a constraint. Instead, we only enforce those practices strictly necessary for most open and reproducible software in science:
-	We do not enforce any specific programming language. However, the only requirement is the general usability of the language on the computer of the practitioner without paying license fees. Therefore, for example MATLAB-based pupil detectors are excluded.
-	We do not enforce any specific hardware setup or operational system. The only assumption is the general runability within Linux-based container. When upon the software âDockerâ, this constraint is fulfilled on Linux, Microsoft Windows and macOS based systems.
-	We do not restrict ourselves to pupil detection algorithms from recent research. Instead, we consider open software explicitly designed for this task, too. Given its growing importance in the field, we consequently consider the popular Pupil software, too.

Under those considerations, we included TODO algorithms into our framework. To the best of our knowledge, this is the largest available group of algorithms for the detection of pupils directly applicable to custom datasets.

### Design of the framework
The minimal atom of the framework are the containers. Those fully independent components include the actual implementation of the pupil detection algorithm. They encapsulate all those parts of the environment the scientists would otherwise require installing themselves on their systems. This includes all the software required to build and execute the code, the dependencies upon other code and data, and the source code itself. Consequently, the programming language and further context are not visible nor of any particular interest. Given their re-usability and independence, the containers are licensed accordingly to their included code and accessibly on their own.

Given the missing information regarding the implementation, rather universal standards are required alternatively for communication and transmission of detections. As a well-established standard, we developed a REST interface for all the pupil detectors included. The usage of HTTP does not only allow the usage of a variety of tools developed for this de-facto standard for the communication with microservice. Furthermore, it allows human-understandable and transparent communication with the algorithms. For ensuring compatibility, we standartized the interface according to the most recent version of the OpenAPI standard. Consequently, this definition and the container are already sufficient for obtaining pupil estimates.

Given those components, all major programming languages supporting a network stack should be able to send samples and recieve predictions. However, further reducing the burdens for applied researchers must consider the procedure of loading and transmitting the samples in a scalable way, too. Therefore, the framework contains a optional software component providing a command line interface. Given an easy readable configuration file, this software allows the parallel and memory-preserving bulk processing optimized for speed. The results stored as JSON could than be loaded into the data analysis code in those programming languages the applied researcher is familar with. 

## Example
## Discussion
