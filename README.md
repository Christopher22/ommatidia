# Ommatidia: Improving generalizability for pupil detection algorithms in head-mounted eye tracking
## Introduction
Eye-tracking is a ubiquitous technology to record, assess, and evaluate eye movements, gazes, and pupil reactions in a magnitude of different research fields [@punde2017]. Historically, corresponding pipelines aimed for otherwise hardly measurable quantities like attention [@TODO] or memory [@TODO]. However, the technology starts to be more widely applied as an invaluable aid for optimized human-computer interaction and experiments in more applied scientific areas like medicine [@larrazabal2019]. Consequently, the growing demand for objective measurements fuels the development of required technology in research and industry [@TODO]. With reduced costs, fewer complexities, and improved accuracy, the technology will presumably get even more prevalent in the future [@TODO].

Stationary eye trackers are generally researched for scientific purposes since the late 19th century [@cognolato2018]. More recently, head-mounted video oculography evolved as a valuable alternative allowing former impossible experimental setups [@cazzato2020a]. Fueled by the minimalization of optical technology, cameras inbuild in glasses-like devices or virtual reality headsets record the eyes constantly with non-visible near-infrared light. Unlike the popular yet proprietary devices used before, the complete process of recording is transparent and re-evaluable accordingly to advances in analysis methods. Additionally, affordable off-the-shelve technology is available or could straightforwardly tailormade [i.e. @zandi2021; @stengel2015]. Consequently, the technology directly supports the four principal components of open science [@vicente-saez2018].

The downside of such great flexibility and archivable tailor-made solutions is the responsibility to tune those magnitudes of factors influencing the actual recording process. Besides the physical camera setup, the pupil detection algorithms represent the primary component of the eye-tracking pipeline. Despite the apparent simplicity of detecting the corresponding blob of pixels in a near-infrared image, this task is challenging and far from being solved. Factors such as contact lenses, dust, makeup, and other external factors induce further complications in the measurement process [@tonsen2016]. Given the magnitude of available algorithms with different advantages and disadvantages, the researcher must choose the method and associated hyperparameters optionally matching its aim [@chen2019]. Guiding those choices given reliable evidence and ease of application define the aim of this publication.

## Challenges with pupil data
Due to various reasons, a decent recording and appropriate analysis of eye-tracking data is not a trivial task. However, those well-known complexities lead to a considerable collection of published knowledge and pieces of advice in literature. Those published insights into possible recording setups, optimization strategies regarding data quality, and analysis methods allow valuable hints towards the proper use of the powerful methodology. Consequently, any researcher striving to apply it could build upon a vivid ecosystem of scientific work.

Supporting the applied researcher in choosing a particular pupil detection algorithm for the measurement pipeline, some evaluation surveys try to compare and rate those algorithms. Using similar evaluation criteria as the developers of the algorithms, the authors provide valuable additional evidence regarding the performance without any bias slipping in unintentionally. In general terms, those reviews document the expected continous improvement of the algorithms due to rising complexity and available data. Still, the ways of analyses do not vary significantly to the original papers. Consequently, the performance of the algorithms is based upon an assumed generalizibility given multiple datasets.

Different datasets for such an evaluation exists due to the diversity of potential recording designs. Most of those were used for training or evaluating a pupil detection algorithm. Consequently, they differ in the types of labels associated with the sample depending on the three major types of algorithms.
Most fundamental is the detected pupil center within the image. Given these two-dimensional coordinates and a (commonly estimated) three-dimensional model of the eye, subsequent procedures can calculate the corresponding rotation of the eye. 
If pupil size matters as in pupillograpy, the algorithms normally yield the best-fitting ellipse enclosing the pupil. The output contains the size of the major and minor axis and its rotation in addition to the two-dimensional position.
The most versatile representation utilizes a segmentation map over the complete sample. This segmentation mask corresponds to a binary mask where only the pupil is indicated. Partly, those algorithm plot algorithms yield output even for other components of the eye like the iris and sclera. In theory, such encoding would allow for partially invisible due to eyelids or blinks.
Crucially, these three different types of annotation create a hierarchy. While the segmentation mask contains most information, reducing it to an ellipse is possible. 

Different datasets for such an evaluation exists due to the diversity of potential recording designs. Most of those were used for training or evaluating a pupil detection algorithm. Consequently, they differ in the types of labels associated with the sample depending on the three major types of algorithms.
Most fundamental is the detected pupil center within the image. Given these two-dimensional coordinates and a (commonly estimated) three-dimensional model of the eye, subsequent procedures can calculate the corresponding rotation of the eye. 
If pupil size matters like in pupillograpy, the algorithms typically yield the best-fitting ellipse enclosing the pupil. The output contains the size of the major and minor axis and its rotation in addition to the two-dimensional position.
The most versatile representation utilizes a segmentation map over the complete sample. This segmentation mask corresponds to a binary mask where only the pupil is indicated. Partially, those algorithms yield similar data for other components of the eye like the iris and sclera, too. In theory, such encoding would even permit using pupils partially hidden due to eyelids or blinks.
Crucially, these three different annotations create a hierarchy regarding their information. While the segmentation mask contains most information, reducing it to an ellipse or even the pupil center is feasible. Given large annotated datasets, researchers rely on the fact algorithms performing well on them will generalize well on unseen setups and subjects, too.

The concept of generalizability is crucial for such an assumption. However, there is no guarantee sufficient performance on other datasets will lead to sufficient performance on the custom setup, too. Instead, different authors highlighted the importance of custom adaptations required for sufficient performance. These complexities result from a magnitude of different aspects:
-   The recorded samples differ significantly based on the position of the camera, its resolution, and distance. Consequently, those of different recording setups are not directly comparable. Given the non-linear transformation of the pupil once viewed from larger eye angles, the performance of the algorithms might be significantly more challenging.
-   The algorithms often require the setting of hyperparameters depending on the samples. Many of those are directly related to semantical meaning ând tailored to the specific position of the camera. While reusing those values published may be sufficient if the setups are similar enough, getting more suitable detections will likely depend upon tuning those values.
-   The population of the subjects may differ considerably. Especially in the medical context, specific correlated phenotypes may seriously hinder the detection rate. Published work like TODO systematically evaluating induced bias is still scarce. Furthermore, even within the general population, such challenges are well-documented [TODO]. As an example, measuring specifically subjects with contact lenses requires detectors to perform well even in this specific condition without inducing any bias.
-   The metrics used for performance evaluation differ significantly between studies. Often, they were chosen for optimally assessing a specific dataset or use case. For instance, the evaluation paper by [TODO] used a threshold of five pixels for classifying the detection of the pupil center inside a sample as correct. Given the tested datasets, this is a thoroughly sound decision. However, samples with significantly different resolutions due to another camera setup require the adoption of such concepts.

Given those complexities, the evaluation of pupil detection algorithms must consider their context. Claiming generally superior performance in direct comparison with all competitors appears challenging. Consequently, custom considerations and evaluations in the application of pupil detection algorithms remain necessary.

Besides the hypothetical overall performance, other key concepts influence the decision in favor of one or another pupil detection algorithm. Those other factors arise analogously to other use cases of machine learning where softer concepts start to play a role, too [@cazzato2020a].
Transparency is an example of such an additional dimension. When applied in sensible medical areas, understanding the reasons regarding a specific output might be required.
Another reason is suitable licensing. Some algorithms are licensed for non-commercial usage only. Even in academia, such a license would be incompatible with classical open-source licenses like the GPL. Their requirement regarding re-licensing under the same terms would probit the proper publication required for transparent science. 
Considering those facts further complicates the appropriate choice of a pupil detector besides the assumed detection performance.

Considering all those factors when choosing one out of the many available pupil detection algorithms remains a challenge. Choosing whether to stick to a popular default or choose and tune the algorithm for optimal performance might depend on the precise specification of the project. However, even the soundest knowledge regarding the literature might not be sufficient in the latter case. Consequently, empowering an applied researcher to select and fit the best-fitting detector for the research is the primary contribution of this paper.

## Unifying framework for the assessment of pupil detection algorithms
The aim of this publication is the empowerment of researchers from various scientific disciplines toward the independent assessment of pupil detection algorithms within their experiments. The corresponding procedure of assessment must be as inclusive as possible. It should be easily usable and must not require detailed knowledge regarding the details of method and implementation. Under the premise, the researcher should be able to optimize the measurements of their raw experimental data for the sake of more sustainable science.

To enforce those central concepts, we defined the required constraints any proposed toolkit must fulfill to be applied effectively in academic practice. Naturally, most of the complexities associated with the evaluation should be handled automatically without manual intervention. However, establishing a sustainable and reusable utility requires a more precise definition regarding the underlying constraints.

- The proposed framework must be as flexible as possible regarding the hardware and software environment for its execution. It must not be required to run on remote servers but allow for full offline use. Allowing for widespread use in all countries, it should not require a specific commercial system that might be inaccessible due to license regulations or fees. Additionally, applied researchers should be able to use it directly on the system already employed for the other parts of the conducted experiment. Avoiding the copies of raw data in different systems may help prevent data loss, respect privacy constraints, and simplify the general knowledge. Consequently, the toolkit must support recent hardware both with UNIX-based operating systems often licensed as Open Source software and with the popular yet proprietary Microsoft Windows.
- Once a suitable system is available, setting up the toolkit should be as straightforward as possible and not require advanced knowledge. While this seems like a trivial task, it is seriously hindered by the different pupil detection algorithms. Available implementations depend upon various programming languages and require a magnitude of different libraries and build tools. Comparable to many of the scripts published in scientific publications, installing all those dependencies is often challenging and time-consuming. Consequently, a manual setup must not be required. Therefore, the results of the assessment are faster and easier to archive.
- The proposed toolkit must be scalable given the large numbers of samples in recent datasets, the variety of different algorithms, and the total sum of tunable hyperparameters. Luckily, the independence of algorithms and samples leads to easily archivable parallelization of the detections. Consequently, the toolkit should be able to benefit from a single machine, multiple virtual machines, and even a cluster of physical devices. Such an ability allows the most efficient exploration of the extensive search space given the available computational resources.
- The toolkit should be modular and base upon existing standards. Sticking to established best practices simplifies the support and supports sustainable development. Additionally, those standards allow the re-use of individual components within the system without requiring the usage of the system as a whole. As an example, after a pupil detector was selected successfully its implementation could be used inside the final experiment, too.
- The toolkit should be easily adaptable not only for those primarily employing pupil detection algorithms but for those developing them. Given the larger number of available competitors, the developers of a new detector may gain important insights for their optimization. Additionally, the risk of involuntary selection bias within the associated publication might be reduced given the strictly reproducible nature. As such, the toolkit may contribute to the sustainable development of the methodological area, too.

Given those constraints, a setup based upon microservices and distributed computing appear appealing. The rest of the section will describe the methodological and technical details of the modular, scalar, and effortlessly adaptable toolkit.

### Selection of the pupil detection algorithms
For a mostly completely collection of state-of-the-art algorithms, we utilize the extensive overview by TODO. The fundamental idea is the assumption of as few assumptions as possible. Realtime processing as sometimes enforced is explicitly not a constraint. Instead, we only enforce those practices strictly necessary for most open and reproducible software in science:
-	We do not enforce any specific programming language. However, the only requirement is the general usability of the language on the computer of the practitioner without paying license fees. Therefore, for example MATLAB-based pupil detectors are excluded.
-	We do not enforce any specific hardware setup or operational system. The only assumption is the general runability within Linux-based container. When upon the software “Docker”, this constraint is fulfilled on Linux, Microsoft Windows and macOS based systems.
-	We do not restrict ourselves to pupil detection algorithms from recent research. Instead, we consider open software explicitly designed for this task, too. Given its growing importance in the field, we consequently consider the popular Pupil software, too.

Under those considerations, we included TODO algorithms into our framework. To the best of our knowledge, this is the largest available group of algorithms for the detection of pupils directly applicable to custom datasets.

### Design of the framework
The minimal atom of the framework are the containers. Those fully independent components include the actual implementation of the pupil detection algorithm. They encapsulate all those parts of the environment the scientists would otherwise require installing themselves on their systems. This includes all the software required to build and execute the code, the dependencies upon other code and data, and the source code itself. Consequently, the programming language and further context are not visible nor of any particular interest. Given their re-usability and independence, the containers are licensed accordingly to their included code and accessibly on their own.

Given the missing information regarding the implementation, rather universal standards are required alternatively for communication and transmission of detections. As a well-established standard, we developed a REST interface for all the pupil detectors included. The usage of HTTP does not only allow the usage of a variety of tools developed for this de-facto standard for the communication with microservice. Furthermore, it allows human-understandable and transparent communication with the algorithms. For ensuring compatibility, we standartized the interface according to the most recent version of the OpenAPI standard. Consequently, this definition and the container are already sufficient for obtaining pupil estimates.

Given those components, all major programming languages supporting a network stack should be able to send samples and recieve predictions. However, further reducing the burdens for applied researchers must consider the procedure of loading and transmitting the samples in a scalable way, too. Therefore, the framework contains a optional software component providing a command line interface. Given an easy readable configuration file, this software allows the parallel and memory-preserving bulk processing optimized for speed. The results stored as JSON could than be loaded into the data analysis code in those programming languages the applied researcher is familar with. 

## Example
## Discussion
